{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Set Up the Environment\n",
    "### 1. Install JAX, Flax, and Optax\n",
    "\n",
    "Create a new Jupyter notebook and start with installing the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jax jaxlib flax optax "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Libraries\n",
    "\n",
    "Start a new notebook cell with necessary imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "from flax.training import train_state\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Loading and Preprocessing\n",
    "\n",
    "### 1. Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')\n",
    "X = mnist.data / 255.0\n",
    "y = mnist.target.astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = [(X_train[i:i + batch_size], y_train[i:i + batch_size]) for i in range(0, len(X_train), batch_size)]\n",
    "test_loader = [(X_test[i:i + batch_size], y_test[i:i + batch_size]) for i in range(0, len(X_test), batch_size)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Definition\n",
    "\n",
    "### 1. Define a Feedforward Neural Network using Flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNN(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = x.reshape((x.shape[0], -1))  # Flatten the input\n",
    "        x = nn.Dense(features=128)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=10)(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Loss Function and Optimizer\n",
    "\n",
    "### 1. Define the Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(logits, labels):\n",
    "    one_hot = jax.nn.one_hot(labels, num_classes=10)\n",
    "    return jnp.mean(optax.softmax_cross_entropy(logits=logits, labels=one_hot))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(rng, learning_rate, model, input_shape):\n",
    "    params = model.init(rng, jnp.ones(input_shape))['params']\n",
    "    tx = optax.adam(learning_rate)\n",
    "    return train_state.TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Training Loop\n",
    "#### 1. Define the Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    def loss_fn(params):\n",
    "        logits = state.apply_fn({'params': params}, batch['image'])\n",
    "        loss = cross_entropy_loss(logits, batch['label'])\n",
    "        return loss\n",
    "    grads = jax.grad(loss_fn)(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Initialize Parameters and Optimizer State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "model = FeedforwardNN()\n",
    "input_shape = (batch_size, 28, 28)\n",
    "state = create_train_state(rng, 0.001, model, input_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 completed.\n",
      "Epoch 2/5 completed.\n",
      "Epoch 3/5 completed.\n",
      "Epoch 4/5 completed.\n",
      "Epoch 5/5 completed.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        batch = {'image': jnp.array(x_batch), 'label': jnp.array(y_batch)}\n",
    "        state = train_step(state, batch)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} completed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Model Evaluation \n",
    "\n",
    "#### 1. Define the Evaluation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def eval_step(params, batch):\n",
    "    logits = model.apply({'params': params}, batch['image'])\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for x_batch, y_batch in test_loader:\n",
    "    batch = {'image': jnp.array(x_batch), 'label': jnp.array(y_batch)}\n",
    "    logits = eval_step(state.params, batch)\n",
    "    predicted = jnp.argmax(logits, axis=1)\n",
    "    total += batch['label'].shape[0]\n",
    "    correct += jnp.sum(predicted == batch['label'])\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Interactive Elements\n",
    "#### 1. Adding Markdown Cells for Explanation\n",
    "##### Use Markdown cells to explain each step, providing context and instructions.\n",
    "\n",
    "#### 2. Interactive Widgets\n",
    "##### Consider using ipywidgets to make the notebook interactive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf41d30dfc2e4dc6a9927a51f4cb33f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.001, description='learning_rate', max=0.003, min=-0.001), IntSlider(â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.train_and_evaluate(learning_rate=0.001, num_epochs=5)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "def train_and_evaluate(learning_rate=0.001, num_epochs=5):\n",
    "    state = create_train_state(rng, learning_rate, model, input_shape)\n",
    "    for epoch in range(num_epochs):\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            batch = {'image': jnp.array(x_batch), 'label': jnp.array(y_batch)}\n",
    "            state = train_step(state, batch)\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs} completed.')\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        batch = {'image': jnp.array(x_batch), 'label': jnp.array(y_batch)}\n",
    "        logits = eval_step(state.params, batch)\n",
    "        predicted = jnp.argmax(logits, axis=1)\n",
    "        total += batch['label'].shape[0]\n",
    "        correct += jnp.sum(predicted == batch['label'])\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    return accuracy\n",
    "\n",
    "interact(train_and_evaluate, learning_rate=0.001, num_epochs=IntSlider(min=1, max=10, step=1, value=5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3113",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
